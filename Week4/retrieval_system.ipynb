{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import background_remover_w2 as background_remover\n",
    "from noise_filter import preprocess_image\n",
    "from image_split import split_images\n",
    "from descriptors import compute_descriptor, create_extractor\n",
    "from keypoints import detect_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3dcbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "IMG_FOLDER = \"../Data/Week4/qsd1_w4/\"\n",
    "IMG_FOLDER_GT = \"../Data/BBDD/\"\n",
    "GT_CORRESPS_PATH = \"../Data/Week4/qsd1_w4/gt_corresps.pkl\"\n",
    "DESC_GT_PATH = \"results/descriptors_gt.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3032f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = \"SIFT\"\n",
    "\n",
    "EXTRACTOR = create_extractor(METHOD)\n",
    "\n",
    "L2NORM = False\n",
    "\n",
    "def _l2norm(x):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    n = np.linalg.norm(x) + 1e-12\n",
    "    return x / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load or compute GT descriptors ---\n",
    "\n",
    "def build_gt_descriptors(gt_folder, extractor):\n",
    "    names = sorted([f for f in os.listdir(gt_folder) if f.lower().endswith(('.jpg'))])\n",
    "    descs = []\n",
    "    for name in names:\n",
    "        print(\"Processing image \",name)\n",
    "        img = cv2.imread(os.path.join(gt_folder, name))\n",
    "        # 1) (Optional) convert BGR->RGB if your descriptors expect RGB\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 2) preprocess (not necessary in gt folder because images doesn't have noise)\n",
    "        # img_p = preprocess_image(img)\n",
    "\n",
    "        # 3) background remover + crop\n",
    "        #im, mask, _, _ = background_remover.remove_background_morphological_gradient(img)\n",
    "        #img_c = background_remover.crop_to_mask_rectangle(im, mask)\n",
    "\n",
    "        # 4) descriptor (L2 normalize)\n",
    "        #kps = detect_keypoints(img_c, METHOD)\n",
    "        d = compute_descriptor(img, None, extractor)\n",
    "        if L2NORM:\n",
    "            d = _l2norm(d)\n",
    "        descs.append(d)\n",
    "    return descs, names\n",
    "\n",
    "\n",
    "if os.path.exists(DESC_GT_PATH):\n",
    "    with open(DESC_GT_PATH, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        desc_gt = data[\"desc_gt\"]\n",
    "        gt_names = data[\"gt_names\"]\n",
    "else:\n",
    "    desc_gt, gt_names = build_gt_descriptors(IMG_FOLDER_GT, EXTRACTOR)\n",
    "    os.makedirs(os.path.dirname(DESC_GT_PATH), exist_ok=True)\n",
    "    with open(DESC_GT_PATH, \"wb\") as f:\n",
    "        pickle.dump({\"desc_gt\": desc_gt, \"gt_names\": gt_names}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load GT correspondences ---\n",
    "with open(GT_CORRESPS_PATH, \"rb\") as f:\n",
    "    gt_corresps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Process all images in the folder ---\n",
    "\n",
    "image_names = sorted([f for f in os.listdir(IMG_FOLDER) if f.endswith('.jpg')])\n",
    "desc_query = []\n",
    "\n",
    "for img_idx, img_name in enumerate(image_names):\n",
    "    print(f\"Processing {img_name} ...\")\n",
    "    img_path = os.path.join(IMG_FOLDER, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Skipping {img_name}: could not read image.\")\n",
    "        continue\n",
    "\n",
    "    # Split possible multiple artworks\n",
    "    splitted = split_images(img)\n",
    "\n",
    "    if splitted[0] is True:\n",
    "        splitted = splitted[1]  # two artworks detected\n",
    "        left_artwork, right_artwork = splitted\n",
    "\n",
    "        left_artwork = preprocess_image(left_artwork)\n",
    "        right_artwork = preprocess_image(right_artwork)\n",
    "\n",
    "        iml, left_mask, left_output, _ = background_remover.remove_background_morphological_gradient(left_artwork)\n",
    "        imr, right_mask, right_output, _ = background_remover.remove_background_morphological_gradient(right_artwork)\n",
    "\n",
    "        # Crop each artwork to its mask bounding box (no black borders)\n",
    "        left_cropped = background_remover.crop_to_mask_rectangle(left_artwork, left_mask)\n",
    "        right_cropped = background_remover.crop_to_mask_rectangle(right_artwork, right_mask)\n",
    "\n",
    "        # Extract descriptors\n",
    "        #kps_left = detect_keypoints(left_cropped, METHOD)\n",
    "        #kps_right = detect_keypoints(right_cropped, METHOD)\n",
    "        \n",
    "        desc_left  = compute_descriptor(left_cropped, None, EXTRACTOR)\n",
    "        desc_right = compute_descriptor(right_cropped, None, EXTRACTOR)\n",
    "        \n",
    "        if L2NORM:\n",
    "            desc_left=_l2norm(desc_left)\n",
    "            desc_right=_l2norm(desc_right)\n",
    "\n",
    "        desc_query.append([desc_left, desc_right])\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(left_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Left Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(right_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Right Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    else:  # single artwork\n",
    "        splitted = splitted[1]  # single artwork\n",
    "        img = preprocess_image(splitted)\n",
    "        im, mask, output, _ = background_remover.remove_background_morphological_gradient(img)\n",
    "\n",
    "        # Crop to mask bounding box (remove black)\n",
    "        cropped = background_remover.crop_to_mask_rectangle(img, mask)\n",
    "\n",
    "        # Extract descriptor\n",
    "        #kps = detect_keypoints(cropped, METHOD)\n",
    "        desc = compute_descriptor(cropped, None, EXTRACTOR)\n",
    "        print(desc)\n",
    "        if L2NORM:\n",
    "            desc = _l2norm(desc)\n",
    "            \n",
    "        desc_query.append([desc])  # keep structure consistent\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"{img_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e69935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Compute mAP@1 and mAP@5 ---\n",
    "def compute_map_at_k(desc_query, desc_gt, gt_corresps, k=5):\n",
    "    query_aps = []\n",
    "\n",
    "    for i, descs in enumerate(desc_query):\n",
    "        # GT for this query\n",
    "        q_gt = gt_corresps[i]\n",
    "        if not isinstance(q_gt, list):\n",
    "            q_gt = [q_gt]\n",
    "\n",
    "        # Lengths\n",
    "        n_crops = len(descs)\n",
    "        n_gts = len(q_gt)\n",
    "\n",
    "        # Make lengths match\n",
    "        if n_crops > n_gts:\n",
    "            # repeat last GT until same length\n",
    "            q_gt = q_gt + [q_gt[-1]] * (n_crops - n_gts)\n",
    "        elif n_crops < n_gts:\n",
    "            # repeat last descriptor until same length\n",
    "            descs = descs + [descs[-1]] * (n_gts - n_crops)\n",
    "\n",
    "        crop_aps = []\n",
    "\n",
    "        # Compute the AP for each image (descriptors taken with their gt labels)\n",
    "        for desc, gt in zip(descs, q_gt):\n",
    "            sims = cosine_similarity([desc], desc_gt)[0]\n",
    "            ranked_indices = np.argsort(-sims)[:k]\n",
    "\n",
    "            # AP for THIS (crop, gt) pair\n",
    "            num_correct = 0\n",
    "            precs = []\n",
    "\n",
    "            for rank, idx in enumerate(ranked_indices, start=1):\n",
    "                if idx == gt:   # exact match for this specific GT\n",
    "                    num_correct += 1\n",
    "                    precs.append(num_correct / rank)\n",
    "\n",
    "            ap = np.sum(precs)\n",
    "            crop_aps.append(ap)\n",
    "\n",
    "        # average over pairs of this query\n",
    "        query_aps.append(float(np.mean(crop_aps)) if crop_aps else 0.0)\n",
    "\n",
    "    # final mAP\n",
    "    return float(np.mean(query_aps)) if query_aps else 0.0\n",
    "map1 = compute_map_at_k(desc_query, desc_gt, gt_corresps, k=1)\n",
    "map5 = compute_map_at_k(desc_query, desc_gt, gt_corresps, k=5)\n",
    "\n",
    "print(f\"\\n✅ mAP@1 = {map1:.4f}\")\n",
    "print(f\"✅ mAP@5 = {map5:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
