{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Retrieval system using HOG descriptors + mAP@1 and mAP@5\n",
    "# This notebook:\n",
    "# 1. Builds (or loads) HOG descriptors for the database (BBDD)\n",
    "# 2. Extracts HOG for the query images\n",
    "# 3. Retrieves the most similar database images using cosine similarity\n",
    "# 4. Evaluates using mAP@1 and mAP@5 based on gt_corresps.pkl\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from noise_filter import preprocess_image\n",
    "import background_remover_w2 as background_remover\n",
    "from image_split import split_images\n",
    "from image_split_team5 import segment_multiple_paintings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- paths (adjust to your structure) ---\n",
    "QUERY_FOLDER = \"../Data/Week4/qsd1_w4/\"     # query images\n",
    "DB_FOLDER    = \"../Data/BBDD/\"        # database (gallery) images\n",
    "GT_PATH      = \"../Data/Week4/qsd1_w4/gt_corresps.pkl\"\n",
    "\n",
    "# where to store precomputed DB descriptors\n",
    "DESC_DB_PATH = \"results/descriptors_db_hog.pkl\"\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea714a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def compute_hog_descriptor(\n",
    "    img_bgr,\n",
    "    size=(128, 128),\n",
    "    cell=(4, 4),\n",
    "    block=(16, 16),\n",
    "    block_stride=(8, 8),\n",
    "    nbins=9,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a HOG descriptor for a BGR image.\n",
    "    We:\n",
    "    1. convert to grayscale\n",
    "    2. resize to a fixed size so all descriptors have the same length\n",
    "    3. compute HOG\n",
    "    4. L2-normalize the final vector\n",
    "    \"\"\"\n",
    "    # 1) BGR -> Gray\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    # 2) fixed resize to make descriptor length stable\n",
    "    gray = cv2.resize(gray, size)\n",
    "\n",
    "    # 3) create HOG object with consistent parameters\n",
    "    hog = cv2.HOGDescriptor(\n",
    "        _winSize=size,\n",
    "        _blockSize=block,\n",
    "        _blockStride=block_stride,\n",
    "        _cellSize=cell,\n",
    "        _nbins=nbins,\n",
    "    )\n",
    "    desc = hog.compute(gray)  # shape (N, 1)\n",
    "    desc = desc.flatten().astype(np.float32)\n",
    "\n",
    "    # 4) L2 normalization (good for cosine and distance-based retrieval)\n",
    "    norm = np.linalg.norm(desc)\n",
    "    if norm > 0:\n",
    "        desc = desc / norm\n",
    "\n",
    "    return desc\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    Loads all .jpg/ images from a folder, sorted by filename.\n",
    "    Returns:\n",
    "        names: list of filenames\n",
    "        imgs:  list of loaded cv2 images\n",
    "    \"\"\"\n",
    "    names = sorted(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(folder)\n",
    "            if f.lower().endswith((\".jpg\"))\n",
    "        ]\n",
    "    )\n",
    "    imgs = []\n",
    "    for name in names:\n",
    "        path = os.path.join(folder, name)\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"âš ï¸ Could not read {path}\")\n",
    "            continue\n",
    "        imgs.append(img)\n",
    "    return names, imgs\n",
    "\n",
    "\n",
    "def precision_at_k(retrieved_indices, gt_indices, k):\n",
    "    \"\"\"\n",
    "    Compute precision@k for one query.\n",
    "\n",
    "    retrieved_indices: list of database indices sorted by similarity (best first)\n",
    "    gt_indices: list of correct database indices for that query (can be 1 or more)\n",
    "    k: cutoff (1, 5, ...)\n",
    "\n",
    "    precision@k = (# of retrieved items in top-k that are in GT) / k\n",
    "    \"\"\"\n",
    "    retrieved_k = retrieved_indices[:k]\n",
    "    hits = sum(1 for r in retrieved_k if r in gt_indices)\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def mean_average_precision_at_k(all_retrieved, all_gts, k):\n",
    "    \"\"\"\n",
    "    Compute mean precision@k over all queries.\n",
    "    (Many assignments call this mAP@k when GT is small.)\n",
    "    \"\"\"\n",
    "    assert len(all_retrieved) == len(all_gts)\n",
    "    precisions = []\n",
    "    for retrieved, gts in zip(all_retrieved, all_gts):\n",
    "        p = precision_at_k(retrieved, gts, k)\n",
    "        precisions.append(p)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "def validate_split(is_split, imgs, min_size_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Validate the result of segment_multiple_paintings.\n",
    "\n",
    "    Parameters:\n",
    "        is_split (bool): Whether the segmentation said it's split.\n",
    "        imgs (list or np.ndarray): List [img1, img2] or a single image.\n",
    "        min_size_ratio (float): Minimum ratio (relative to original image width/height)\n",
    "                                for a crop to be considered valid.\n",
    "    Returns:\n",
    "        (bool, list or np.ndarray): same format as input but corrected.\n",
    "    \"\"\"\n",
    "    # If no split, nothing to do\n",
    "    if not is_split:\n",
    "        return False, imgs\n",
    "\n",
    "    # If there are not exactly 2 images, return as not split\n",
    "    if not isinstance(imgs, (list, tuple)) or len(imgs) != 2:\n",
    "        return False, imgs\n",
    "\n",
    "    img1, img2 = imgs\n",
    "\n",
    "    # Compute relative sizes compared to original (assume same height)\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    total_width = w1 + w2\n",
    "    total_height = max(h1, h2)\n",
    "\n",
    "    # Check each crop relative to the original combined width\n",
    "    valid_left  = w1 / total_width  > min_size_ratio\n",
    "    valid_right = w2 / total_width  > min_size_ratio\n",
    "    valid_height1 = h1 / total_height > min_size_ratio\n",
    "    valid_height2 = h2 / total_height > min_size_ratio\n",
    "\n",
    "    # Only keep crops that are not too small\n",
    "    valid_imgs = []\n",
    "    if valid_left and valid_height1:\n",
    "        valid_imgs.append(img1)\n",
    "    if valid_right and valid_height2:\n",
    "        valid_imgs.append(img2)\n",
    "\n",
    "    # Decide if it's still a valid split\n",
    "    if len(valid_imgs) == 2:\n",
    "        return True, valid_imgs\n",
    "    elif len(valid_imgs) == 1:\n",
    "        # Only one valid crop left â†’ treat as not split\n",
    "        return False, valid_imgs[0]\n",
    "    else:\n",
    "        # none valid? probably invalid segmentation\n",
    "        return False, imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74637338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# 1. Build or load database descriptors (HOG)\n",
    "\n",
    "if os.path.exists(DESC_DB_PATH):\n",
    "    print(f\"âœ… Loading DB descriptors from {DESC_DB_PATH}\")\n",
    "    with open(DESC_DB_PATH, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        db_descs = data[\"desc_gt\"]    # list of numpy arrays\n",
    "        db_names = data[\"gt_names\"]   # list of image filenames\n",
    "else:\n",
    "    print(\"ðŸ§  Computing HOG descriptors for database images...\")\n",
    "    db_names, db_imgs = load_images_from_folder(DB_FOLDER)\n",
    "    db_descs = []\n",
    "    for img, name in zip(db_imgs, db_names):\n",
    "        print(\"Processing image\",name)\n",
    "        d = compute_hog_descriptor(img)\n",
    "        db_descs.append(d)\n",
    "\n",
    "    # store only numpy arrays (serializable) â†’ no cv2.KeyPoint here\n",
    "    with open(DESC_DB_PATH, \"wb\") as f:\n",
    "        pickle.dump({\"desc_gt\": db_descs, \"gt_names\": db_names}, f)\n",
    "    print(f\"âœ… Saved DB descriptors to {DESC_DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. Load query images and ground-truth correspondences\n",
    "\n",
    "print(\"ðŸ“¥ Loading query images...\")\n",
    "q_names, q_imgs = load_images_from_folder(QUERY_FOLDER)\n",
    "\n",
    "print(\"ðŸ“¥ Loading ground-truth correspondences...\")\n",
    "with open(GT_PATH, \"rb\") as f:\n",
    "    gt_corresps = pickle.load(f)   # e.g. [[236], [107], [280, 285], ...]\n",
    "print(f\"â†’ {len(gt_corresps)} GT entries loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc048f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 3. Compute HOG descriptors for queries\n",
    "\n",
    "print(\"ðŸ§  Computing HOG for queries...\")\n",
    "desc_query = []\n",
    "for img, img_name in zip(q_imgs, q_names):\n",
    "    print(\"Processing image\",img_name)\n",
    "    # Split possible multiple artworks\n",
    "    img=preprocess_image(img)\n",
    "    bool_split, splitted_imgs = segment_multiple_paintings(img)\n",
    "    \n",
    "    bool_val, imgs_val = validate_split(bool_split, splitted_imgs)\n",
    "\n",
    "    if bool_val is True:\n",
    "        splitted = imgs_val  # two artworks detected\n",
    "        left_artwork, right_artwork = splitted\n",
    "\n",
    "        iml, left_mask, left_output, _ = background_remover.remove_background_morphological_gradient(left_artwork)\n",
    "        imr, right_mask, right_output, _ = background_remover.remove_background_morphological_gradient(right_artwork)\n",
    "\n",
    "        # Crop each artwork to its mask bounding box (no black borders)\n",
    "        left_cropped = background_remover.crop_to_mask_rectangle(left_artwork, left_mask)\n",
    "        right_cropped = background_remover.crop_to_mask_rectangle(right_artwork, right_mask)\n",
    "\n",
    "        # Extract descriptors\n",
    "        #kps_left = detect_keypoints(left_cropped, METHOD)\n",
    "        #kps_right = detect_keypoints(right_cropped, METHOD)\n",
    "        \n",
    "        desc_left  = compute_hog_descriptor(left_cropped)\n",
    "        desc_right = compute_hog_descriptor(right_cropped)\n",
    "\n",
    "        desc_query.append([desc_left, desc_right])\n",
    "        \n",
    "        \"\"\"plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(left_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Left Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(right_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Right Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\"\"\"\n",
    "\n",
    "    else:  # single artwork\n",
    "        splitted = imgs_val\n",
    "        im, mask, output, _ = background_remover.remove_background_morphological_gradient(img)\n",
    "\n",
    "        # Crop to mask bounding box (remove black)\n",
    "        cropped = background_remover.crop_to_mask_rectangle(img, mask)\n",
    "\n",
    "        # Extract descriptor\n",
    "        #kps = detect_keypoints(cropped, METHOD)\n",
    "        desc = compute_hog_descriptor(cropped)\n",
    "            \n",
    "        desc_query.append([desc])  # keep structure consistent\n",
    "        \n",
    "        \"\"\"plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"{img_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "# stack DB descriptors into a matrix so cosine_similarity is fast\n",
    "db_mat = np.vstack(db_descs)   # shape (N_db, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Compute mAP@1 and mAP@5 ---\n",
    "def compute_map_at_k(desc_query, desc_gt, gt_corresps, k=5):\n",
    "    query_aps = []\n",
    "\n",
    "    for i, descs in enumerate(desc_query):\n",
    "        # GT for this query\n",
    "        q_gt = gt_corresps[i]\n",
    "        if not isinstance(q_gt, list):\n",
    "            q_gt = [q_gt]\n",
    "\n",
    "        # Lengths\n",
    "        n_crops = len(descs)\n",
    "        n_gts = len(q_gt)\n",
    "\n",
    "        # Make lengths match\n",
    "        if n_crops > n_gts:\n",
    "            # repeat last GT until same length\n",
    "            q_gt = q_gt + [q_gt[-1]] * (n_crops - n_gts)\n",
    "        elif n_crops < n_gts:\n",
    "            # repeat last descriptor until same length\n",
    "            descs = descs + [descs[-1]] * (n_gts - n_crops)\n",
    "\n",
    "        crop_aps = []\n",
    "\n",
    "        # Compute the AP for each image (descriptors taken with their gt labels)\n",
    "        for desc, gt in zip(descs, q_gt):\n",
    "            sims = cosine_similarity([desc], desc_gt)[0]\n",
    "            ranked_indices = np.argsort(-sims)[:k]\n",
    "\n",
    "            # AP for THIS (crop, gt) pair\n",
    "            num_correct = 0\n",
    "            precs = []\n",
    "\n",
    "            for rank, idx in enumerate(ranked_indices, start=1):\n",
    "                if idx == gt:   # exact match for this specific GT\n",
    "                    num_correct += 1\n",
    "                    precs.append(num_correct / rank)\n",
    "\n",
    "            ap = np.sum(precs)\n",
    "            crop_aps.append(ap)\n",
    "\n",
    "        # average over pairs of this query\n",
    "        query_aps.append(float(np.mean(crop_aps)) if crop_aps else 0.0)\n",
    "\n",
    "    # final mAP\n",
    "    return float(np.mean(query_aps)) if query_aps else 0.0\n",
    "\n",
    "\n",
    "map1 = compute_map_at_k(desc_query, db_descs, gt_corresps, k=1)\n",
    "map5 = compute_map_at_k(desc_query, db_descs, gt_corresps, k=5)\n",
    "\n",
    "print(f\"\\nâœ… mAP@1 = {map1:.4f}\")\n",
    "print(f\"âœ… mAP@5 = {map5:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
