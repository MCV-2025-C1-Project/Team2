{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e0c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Retrieval system using HOG descriptors + mAP@1 and mAP@5\n",
    "# This notebook:\n",
    "# 1. Builds (or loads) HOG descriptors for the database (BBDD)\n",
    "# 2. Extracts HOG for the query images\n",
    "# 3. Retrieves the most similar database images using cosine similarity\n",
    "# 4. Evaluates using mAP@1 and mAP@5 based on gt_corresps.pkl\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from noise_filter import preprocess_image\n",
    "import background_remover_w2 as background_remover\n",
    "from image_split import split_images\n",
    "from image_split_team5 import segment_multiple_paintings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- paths (adjust to your structure) ---\n",
    "QUERY_FOLDER = \"../Data/Week4/qsd1_w4/\"     # query images\n",
    "DB_FOLDER    = \"../Data/BBDD/\"        # database (gallery) images\n",
    "GT_PATH      = \"../Data/Week4/qsd1_w4/gt_corresps.pkl\"\n",
    "\n",
    "# where to store precomputed DB descriptors\n",
    "DESC_DB_PATH = \"results/descriptors_db_hog.pkl\"\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea714a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def compute_hog_descriptor(\n",
    "    img_bgr,\n",
    "    size=(128, 128),\n",
    "    cell=(4, 4),\n",
    "    block=(16, 16),\n",
    "    block_stride=(8, 8),\n",
    "    nbins=9,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a HOG descriptor for a BGR image.\n",
    "    We:\n",
    "    1. convert to grayscale\n",
    "    2. resize to a fixed size so all descriptors have the same length\n",
    "    3. compute HOG\n",
    "    4. L2-normalize the final vector\n",
    "    \"\"\"\n",
    "    # 1) BGR -> Gray\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    # 2) fixed resize to make descriptor length stable\n",
    "    gray = cv2.resize(gray, size)\n",
    "\n",
    "    # 3) create HOG object with consistent parameters\n",
    "    hog = cv2.HOGDescriptor(\n",
    "        _winSize=size,\n",
    "        _blockSize=block,\n",
    "        _blockStride=block_stride,\n",
    "        _cellSize=cell,\n",
    "        _nbins=nbins,\n",
    "    )\n",
    "    desc = hog.compute(gray)  # shape (N, 1)\n",
    "    desc = desc.flatten().astype(np.float32)\n",
    "\n",
    "    # 4) L2 normalization (good for cosine and distance-based retrieval)\n",
    "    norm = np.linalg.norm(desc)\n",
    "    if norm > 0:\n",
    "        desc = desc / norm\n",
    "\n",
    "    return desc\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    Loads all .jpg/ images from a folder, sorted by filename.\n",
    "    Returns:\n",
    "        names: list of filenames\n",
    "        imgs:  list of loaded cv2 images\n",
    "    \"\"\"\n",
    "    names = sorted(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(folder)\n",
    "            if f.lower().endswith((\".jpg\"))\n",
    "        ]\n",
    "    )\n",
    "    imgs = []\n",
    "    for name in names:\n",
    "        path = os.path.join(folder, name)\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"⚠️ Could not read {path}\")\n",
    "            continue\n",
    "        imgs.append(img)\n",
    "    return names, imgs\n",
    "\n",
    "\n",
    "def precision_at_k(retrieved_indices, gt_indices, k):\n",
    "    \"\"\"\n",
    "    Compute precision@k for one query.\n",
    "\n",
    "    retrieved_indices: list of database indices sorted by similarity (best first)\n",
    "    gt_indices: list of correct database indices for that query (can be 1 or more)\n",
    "    k: cutoff (1, 5, ...)\n",
    "\n",
    "    precision@k = (# of retrieved items in top-k that are in GT) / k\n",
    "    \"\"\"\n",
    "    retrieved_k = retrieved_indices[:k]\n",
    "    hits = sum(1 for r in retrieved_k if r in gt_indices)\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def mean_average_precision_at_k(all_retrieved, all_gts, k):\n",
    "    \"\"\"\n",
    "    Compute mean precision@k over all queries.\n",
    "    (Many assignments call this mAP@k when GT is small.)\n",
    "    \"\"\"\n",
    "    assert len(all_retrieved) == len(all_gts)\n",
    "    precisions = []\n",
    "    for retrieved, gts in zip(all_retrieved, all_gts):\n",
    "        p = precision_at_k(retrieved, gts, k)\n",
    "        precisions.append(p)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "def validate_split(is_split, imgs, min_size_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Validate the result of segment_multiple_paintings.\n",
    "\n",
    "    Parameters:\n",
    "        is_split (bool): Whether the segmentation said it's split.\n",
    "        imgs (list or np.ndarray): List [img1, img2] or a single image.\n",
    "        min_size_ratio (float): Minimum ratio (relative to original image width/height)\n",
    "                                for a crop to be considered valid.\n",
    "    Returns:\n",
    "        (bool, list or np.ndarray): same format as input but corrected.\n",
    "    \"\"\"\n",
    "    # If no split, nothing to do\n",
    "    if not is_split:\n",
    "        return False, imgs\n",
    "\n",
    "    # If there are not exactly 2 images, return as not split\n",
    "    if not isinstance(imgs, (list, tuple)) or len(imgs) != 2:\n",
    "        return False, imgs\n",
    "\n",
    "    img1, img2 = imgs\n",
    "\n",
    "    # Compute relative sizes compared to original (assume same height)\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    total_width = w1 + w2\n",
    "    total_height = max(h1, h2)\n",
    "\n",
    "    # Check each crop relative to the original combined width\n",
    "    valid_left  = w1 / total_width  > min_size_ratio\n",
    "    valid_right = w2 / total_width  > min_size_ratio\n",
    "    valid_height1 = h1 / total_height > min_size_ratio\n",
    "    valid_height2 = h2 / total_height > min_size_ratio\n",
    "\n",
    "    # Only keep crops that are not too small\n",
    "    valid_imgs = []\n",
    "    if valid_left and valid_height1:\n",
    "        valid_imgs.append(img1)\n",
    "    if valid_right and valid_height2:\n",
    "        valid_imgs.append(img2)\n",
    "\n",
    "    # Decide if it's still a valid split\n",
    "    if len(valid_imgs) == 2:\n",
    "        return True, valid_imgs\n",
    "    elif len(valid_imgs) == 1:\n",
    "        # Only one valid crop left → treat as not split\n",
    "        return False, valid_imgs[0]\n",
    "    else:\n",
    "        # none valid? probably invalid segmentation\n",
    "        return False, imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74637338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Computing HOG descriptors for database images...\n",
      "Processing image bbdd_00000.jpg\n",
      "Processing image bbdd_00001.jpg\n",
      "Processing image bbdd_00002.jpg\n",
      "Processing image bbdd_00003.jpg\n",
      "Processing image bbdd_00004.jpg\n",
      "Processing image bbdd_00005.jpg\n",
      "Processing image bbdd_00006.jpg\n",
      "Processing image bbdd_00007.jpg\n",
      "Processing image bbdd_00008.jpg\n",
      "Processing image bbdd_00009.jpg\n",
      "Processing image bbdd_00010.jpg\n",
      "Processing image bbdd_00011.jpg\n",
      "Processing image bbdd_00012.jpg\n",
      "Processing image bbdd_00013.jpg\n",
      "Processing image bbdd_00014.jpg\n",
      "Processing image bbdd_00015.jpg\n",
      "Processing image bbdd_00016.jpg\n",
      "Processing image bbdd_00017.jpg\n",
      "Processing image bbdd_00018.jpg\n",
      "Processing image bbdd_00019.jpg\n",
      "Processing image bbdd_00020.jpg\n",
      "Processing image bbdd_00021.jpg\n",
      "Processing image bbdd_00022.jpg\n",
      "Processing image bbdd_00023.jpg\n",
      "Processing image bbdd_00024.jpg\n",
      "Processing image bbdd_00025.jpg\n",
      "Processing image bbdd_00026.jpg\n",
      "Processing image bbdd_00027.jpg\n",
      "Processing image bbdd_00028.jpg\n",
      "Processing image bbdd_00029.jpg\n",
      "Processing image bbdd_00030.jpg\n",
      "Processing image bbdd_00031.jpg\n",
      "Processing image bbdd_00032.jpg\n",
      "Processing image bbdd_00033.jpg\n",
      "Processing image bbdd_00034.jpg\n",
      "Processing image bbdd_00035.jpg\n",
      "Processing image bbdd_00036.jpg\n",
      "Processing image bbdd_00037.jpg\n",
      "Processing image bbdd_00038.jpg\n",
      "Processing image bbdd_00039.jpg\n",
      "Processing image bbdd_00040.jpg\n",
      "Processing image bbdd_00041.jpg\n",
      "Processing image bbdd_00042.jpg\n",
      "Processing image bbdd_00043.jpg\n",
      "Processing image bbdd_00044.jpg\n",
      "Processing image bbdd_00045.jpg\n",
      "Processing image bbdd_00046.jpg\n",
      "Processing image bbdd_00047.jpg\n",
      "Processing image bbdd_00048.jpg\n",
      "Processing image bbdd_00049.jpg\n",
      "Processing image bbdd_00050.jpg\n",
      "Processing image bbdd_00051.jpg\n",
      "Processing image bbdd_00052.jpg\n",
      "Processing image bbdd_00053.jpg\n",
      "Processing image bbdd_00054.jpg\n",
      "Processing image bbdd_00055.jpg\n",
      "Processing image bbdd_00056.jpg\n",
      "Processing image bbdd_00057.jpg\n",
      "Processing image bbdd_00058.jpg\n",
      "Processing image bbdd_00059.jpg\n",
      "Processing image bbdd_00060.jpg\n",
      "Processing image bbdd_00061.jpg\n",
      "Processing image bbdd_00062.jpg\n",
      "Processing image bbdd_00063.jpg\n",
      "Processing image bbdd_00064.jpg\n",
      "Processing image bbdd_00065.jpg\n",
      "Processing image bbdd_00066.jpg\n",
      "Processing image bbdd_00067.jpg\n",
      "Processing image bbdd_00068.jpg\n",
      "Processing image bbdd_00069.jpg\n",
      "Processing image bbdd_00070.jpg\n",
      "Processing image bbdd_00071.jpg\n",
      "Processing image bbdd_00072.jpg\n",
      "Processing image bbdd_00073.jpg\n",
      "Processing image bbdd_00074.jpg\n",
      "Processing image bbdd_00075.jpg\n",
      "Processing image bbdd_00076.jpg\n",
      "Processing image bbdd_00077.jpg\n",
      "Processing image bbdd_00078.jpg\n",
      "Processing image bbdd_00079.jpg\n",
      "Processing image bbdd_00080.jpg\n",
      "Processing image bbdd_00081.jpg\n",
      "Processing image bbdd_00082.jpg\n",
      "Processing image bbdd_00083.jpg\n",
      "Processing image bbdd_00084.jpg\n",
      "Processing image bbdd_00085.jpg\n",
      "Processing image bbdd_00086.jpg\n",
      "Processing image bbdd_00087.jpg\n",
      "Processing image bbdd_00088.jpg\n",
      "Processing image bbdd_00089.jpg\n",
      "Processing image bbdd_00090.jpg\n",
      "Processing image bbdd_00091.jpg\n",
      "Processing image bbdd_00092.jpg\n",
      "Processing image bbdd_00093.jpg\n",
      "Processing image bbdd_00094.jpg\n",
      "Processing image bbdd_00095.jpg\n",
      "Processing image bbdd_00096.jpg\n",
      "Processing image bbdd_00097.jpg\n",
      "Processing image bbdd_00098.jpg\n",
      "Processing image bbdd_00099.jpg\n",
      "Processing image bbdd_00100.jpg\n",
      "Processing image bbdd_00101.jpg\n",
      "Processing image bbdd_00102.jpg\n",
      "Processing image bbdd_00103.jpg\n",
      "Processing image bbdd_00104.jpg\n",
      "Processing image bbdd_00105.jpg\n",
      "Processing image bbdd_00106.jpg\n",
      "Processing image bbdd_00107.jpg\n",
      "Processing image bbdd_00108.jpg\n",
      "Processing image bbdd_00109.jpg\n",
      "Processing image bbdd_00110.jpg\n",
      "Processing image bbdd_00111.jpg\n",
      "Processing image bbdd_00112.jpg\n",
      "Processing image bbdd_00113.jpg\n",
      "Processing image bbdd_00114.jpg\n",
      "Processing image bbdd_00115.jpg\n",
      "Processing image bbdd_00116.jpg\n",
      "Processing image bbdd_00117.jpg\n",
      "Processing image bbdd_00118.jpg\n",
      "Processing image bbdd_00119.jpg\n",
      "Processing image bbdd_00120.jpg\n",
      "Processing image bbdd_00121.jpg\n",
      "Processing image bbdd_00122.jpg\n",
      "Processing image bbdd_00123.jpg\n",
      "Processing image bbdd_00124.jpg\n",
      "Processing image bbdd_00125.jpg\n",
      "Processing image bbdd_00126.jpg\n",
      "Processing image bbdd_00127.jpg\n",
      "Processing image bbdd_00128.jpg\n",
      "Processing image bbdd_00129.jpg\n",
      "Processing image bbdd_00130.jpg\n",
      "Processing image bbdd_00131.jpg\n",
      "Processing image bbdd_00132.jpg\n",
      "Processing image bbdd_00133.jpg\n",
      "Processing image bbdd_00134.jpg\n",
      "Processing image bbdd_00135.jpg\n",
      "Processing image bbdd_00136.jpg\n",
      "Processing image bbdd_00137.jpg\n",
      "Processing image bbdd_00138.jpg\n",
      "Processing image bbdd_00139.jpg\n",
      "Processing image bbdd_00140.jpg\n",
      "Processing image bbdd_00141.jpg\n",
      "Processing image bbdd_00142.jpg\n",
      "Processing image bbdd_00143.jpg\n",
      "Processing image bbdd_00144.jpg\n",
      "Processing image bbdd_00145.jpg\n",
      "Processing image bbdd_00146.jpg\n",
      "Processing image bbdd_00147.jpg\n",
      "Processing image bbdd_00148.jpg\n",
      "Processing image bbdd_00149.jpg\n",
      "Processing image bbdd_00150.jpg\n",
      "Processing image bbdd_00151.jpg\n",
      "Processing image bbdd_00152.jpg\n",
      "Processing image bbdd_00153.jpg\n",
      "Processing image bbdd_00154.jpg\n",
      "Processing image bbdd_00155.jpg\n",
      "Processing image bbdd_00156.jpg\n",
      "Processing image bbdd_00157.jpg\n",
      "Processing image bbdd_00158.jpg\n",
      "Processing image bbdd_00159.jpg\n",
      "Processing image bbdd_00160.jpg\n",
      "Processing image bbdd_00161.jpg\n",
      "Processing image bbdd_00162.jpg\n",
      "Processing image bbdd_00163.jpg\n",
      "Processing image bbdd_00164.jpg\n",
      "Processing image bbdd_00165.jpg\n",
      "Processing image bbdd_00166.jpg\n",
      "Processing image bbdd_00167.jpg\n",
      "Processing image bbdd_00168.jpg\n",
      "Processing image bbdd_00169.jpg\n",
      "Processing image bbdd_00170.jpg\n",
      "Processing image bbdd_00171.jpg\n",
      "Processing image bbdd_00172.jpg\n",
      "Processing image bbdd_00173.jpg\n",
      "Processing image bbdd_00174.jpg\n",
      "Processing image bbdd_00175.jpg\n",
      "Processing image bbdd_00176.jpg\n",
      "Processing image bbdd_00177.jpg\n",
      "Processing image bbdd_00178.jpg\n",
      "Processing image bbdd_00179.jpg\n",
      "Processing image bbdd_00180.jpg\n",
      "Processing image bbdd_00181.jpg\n",
      "Processing image bbdd_00182.jpg\n",
      "Processing image bbdd_00183.jpg\n",
      "Processing image bbdd_00184.jpg\n",
      "Processing image bbdd_00185.jpg\n",
      "Processing image bbdd_00186.jpg\n",
      "Processing image bbdd_00187.jpg\n",
      "Processing image bbdd_00188.jpg\n",
      "Processing image bbdd_00189.jpg\n",
      "Processing image bbdd_00190.jpg\n",
      "Processing image bbdd_00191.jpg\n",
      "Processing image bbdd_00192.jpg\n",
      "Processing image bbdd_00193.jpg\n",
      "Processing image bbdd_00194.jpg\n",
      "Processing image bbdd_00195.jpg\n",
      "Processing image bbdd_00196.jpg\n",
      "Processing image bbdd_00197.jpg\n",
      "Processing image bbdd_00198.jpg\n",
      "Processing image bbdd_00199.jpg\n",
      "Processing image bbdd_00200.jpg\n",
      "Processing image bbdd_00201.jpg\n",
      "Processing image bbdd_00202.jpg\n",
      "Processing image bbdd_00203.jpg\n",
      "Processing image bbdd_00204.jpg\n",
      "Processing image bbdd_00205.jpg\n",
      "Processing image bbdd_00206.jpg\n",
      "Processing image bbdd_00207.jpg\n",
      "Processing image bbdd_00208.jpg\n",
      "Processing image bbdd_00209.jpg\n",
      "Processing image bbdd_00210.jpg\n",
      "Processing image bbdd_00211.jpg\n",
      "Processing image bbdd_00212.jpg\n",
      "Processing image bbdd_00213.jpg\n",
      "Processing image bbdd_00214.jpg\n",
      "Processing image bbdd_00215.jpg\n",
      "Processing image bbdd_00216.jpg\n",
      "Processing image bbdd_00217.jpg\n",
      "Processing image bbdd_00218.jpg\n",
      "Processing image bbdd_00219.jpg\n",
      "Processing image bbdd_00220.jpg\n",
      "Processing image bbdd_00221.jpg\n",
      "Processing image bbdd_00222.jpg\n",
      "Processing image bbdd_00223.jpg\n",
      "Processing image bbdd_00224.jpg\n",
      "Processing image bbdd_00225.jpg\n",
      "Processing image bbdd_00226.jpg\n",
      "Processing image bbdd_00227.jpg\n",
      "Processing image bbdd_00228.jpg\n",
      "Processing image bbdd_00229.jpg\n",
      "Processing image bbdd_00230.jpg\n",
      "Processing image bbdd_00231.jpg\n",
      "Processing image bbdd_00232.jpg\n",
      "Processing image bbdd_00233.jpg\n",
      "Processing image bbdd_00234.jpg\n",
      "Processing image bbdd_00235.jpg\n",
      "Processing image bbdd_00236.jpg\n",
      "Processing image bbdd_00237.jpg\n",
      "Processing image bbdd_00238.jpg\n",
      "Processing image bbdd_00239.jpg\n",
      "Processing image bbdd_00240.jpg\n",
      "Processing image bbdd_00241.jpg\n",
      "Processing image bbdd_00242.jpg\n",
      "Processing image bbdd_00243.jpg\n",
      "Processing image bbdd_00244.jpg\n",
      "Processing image bbdd_00245.jpg\n",
      "Processing image bbdd_00246.jpg\n",
      "Processing image bbdd_00247.jpg\n",
      "Processing image bbdd_00248.jpg\n",
      "Processing image bbdd_00249.jpg\n",
      "Processing image bbdd_00250.jpg\n",
      "Processing image bbdd_00251.jpg\n",
      "Processing image bbdd_00252.jpg\n",
      "Processing image bbdd_00253.jpg\n",
      "Processing image bbdd_00254.jpg\n",
      "Processing image bbdd_00255.jpg\n",
      "Processing image bbdd_00256.jpg\n",
      "Processing image bbdd_00257.jpg\n",
      "Processing image bbdd_00258.jpg\n",
      "Processing image bbdd_00259.jpg\n",
      "Processing image bbdd_00260.jpg\n",
      "Processing image bbdd_00261.jpg\n",
      "Processing image bbdd_00262.jpg\n",
      "Processing image bbdd_00263.jpg\n",
      "Processing image bbdd_00264.jpg\n",
      "Processing image bbdd_00265.jpg\n",
      "Processing image bbdd_00266.jpg\n",
      "Processing image bbdd_00267.jpg\n",
      "Processing image bbdd_00268.jpg\n",
      "Processing image bbdd_00269.jpg\n",
      "Processing image bbdd_00270.jpg\n",
      "Processing image bbdd_00271.jpg\n",
      "Processing image bbdd_00272.jpg\n",
      "Processing image bbdd_00273.jpg\n",
      "Processing image bbdd_00274.jpg\n",
      "Processing image bbdd_00275.jpg\n",
      "Processing image bbdd_00276.jpg\n",
      "Processing image bbdd_00277.jpg\n",
      "Processing image bbdd_00278.jpg\n",
      "Processing image bbdd_00279.jpg\n",
      "Processing image bbdd_00280.jpg\n",
      "Processing image bbdd_00281.jpg\n",
      "Processing image bbdd_00282.jpg\n",
      "Processing image bbdd_00283.jpg\n",
      "Processing image bbdd_00284.jpg\n",
      "Processing image bbdd_00285.jpg\n",
      "Processing image bbdd_00286.jpg\n",
      "✅ Saved DB descriptors to results/descriptors_db_hog.pkl\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "# 1. Build or load database descriptors (HOG)\n",
    "\n",
    "if os.path.exists(DESC_DB_PATH):\n",
    "    print(f\"✅ Loading DB descriptors from {DESC_DB_PATH}\")\n",
    "    with open(DESC_DB_PATH, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        db_descs = data[\"desc_gt\"]    # list of numpy arrays\n",
    "        db_names = data[\"gt_names\"]   # list of image filenames\n",
    "else:\n",
    "    print(\"🧠 Computing HOG descriptors for database images...\")\n",
    "    db_names, db_imgs = load_images_from_folder(DB_FOLDER)\n",
    "    db_descs = []\n",
    "    for img, name in zip(db_imgs, db_names):\n",
    "        print(\"Processing image\",name)\n",
    "        d = compute_hog_descriptor(img)\n",
    "        db_descs.append(d)\n",
    "\n",
    "    # store only numpy arrays (serializable) → no cv2.KeyPoint here\n",
    "    with open(DESC_DB_PATH, \"wb\") as f:\n",
    "        pickle.dump({\"desc_gt\": db_descs, \"gt_names\": db_names}, f)\n",
    "    print(f\"✅ Saved DB descriptors to {DESC_DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65aa4876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading query images...\n",
      "📥 Loading ground-truth correspondences...\n",
      "→ 30 GT entries loaded\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 2. Load query images and ground-truth correspondences\n",
    "\n",
    "print(\"📥 Loading query images...\")\n",
    "q_names, q_imgs = load_images_from_folder(QUERY_FOLDER)\n",
    "\n",
    "print(\"📥 Loading ground-truth correspondences...\")\n",
    "with open(GT_PATH, \"rb\") as f:\n",
    "    gt_corresps = pickle.load(f)   # e.g. [[236], [107], [280, 285], ...]\n",
    "print(f\"→ {len(gt_corresps)} GT entries loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc048f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Computing HOG for queries...\n",
      "Processing image 00000.jpg\n",
      "Processing image 00001.jpg\n",
      "Processing image 00002.jpg\n",
      "Processing image 00003.jpg\n",
      "Processing image 00004.jpg\n",
      "Processing image 00005.jpg\n",
      "Processing image 00006.jpg\n",
      "Processing image 00007.jpg\n",
      "Processing image 00008.jpg\n",
      "Processing image 00009.jpg\n",
      "Processing image 00010.jpg\n",
      "Processing image 00011.jpg\n",
      "Processing image 00012.jpg\n",
      "Processing image 00013.jpg\n",
      "Processing image 00014.jpg\n",
      "Processing image 00015.jpg\n",
      "Processing image 00016.jpg\n",
      "Processing image 00017.jpg\n",
      "Processing image 00018.jpg\n",
      "Processing image 00019.jpg\n",
      "Processing image 00020.jpg\n",
      "Processing image 00021.jpg\n",
      "Processing image 00022.jpg\n",
      "Processing image 00023.jpg\n",
      "Processing image 00024.jpg\n",
      "Processing image 00025.jpg\n",
      "Processing image 00026.jpg\n",
      "Processing image 00027.jpg\n",
      "Processing image 00028.jpg\n",
      "Processing image 00029.jpg\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. Compute HOG descriptors for queries\n",
    "\n",
    "print(\"🧠 Computing HOG for queries...\")\n",
    "desc_query = []\n",
    "for img, img_name in zip(q_imgs, q_names):\n",
    "    print(\"Processing image\",img_name)\n",
    "    # Split possible multiple artworks\n",
    "    img=preprocess_image(img)\n",
    "    bool_split, splitted_imgs = segment_multiple_paintings(img)\n",
    "    \n",
    "    bool_val, imgs_val = validate_split(bool_split, splitted_imgs)\n",
    "\n",
    "    if bool_val is True:\n",
    "        splitted = imgs_val  # two artworks detected\n",
    "        left_artwork, right_artwork = splitted\n",
    "\n",
    "        iml, left_mask, left_output, _ = background_remover.remove_background_morphological_gradient(left_artwork)\n",
    "        imr, right_mask, right_output, _ = background_remover.remove_background_morphological_gradient(right_artwork)\n",
    "\n",
    "        # Crop each artwork to its mask bounding box (no black borders)\n",
    "        left_cropped = background_remover.crop_to_mask_rectangle(left_artwork, left_mask)\n",
    "        right_cropped = background_remover.crop_to_mask_rectangle(right_artwork, right_mask)\n",
    "\n",
    "        # Extract descriptors\n",
    "        #kps_left = detect_keypoints(left_cropped, METHOD)\n",
    "        #kps_right = detect_keypoints(right_cropped, METHOD)\n",
    "        \n",
    "        desc_left  = compute_hog_descriptor(left_cropped)\n",
    "        desc_right = compute_hog_descriptor(right_cropped)\n",
    "\n",
    "        desc_query.append([desc_left, desc_right])\n",
    "        \n",
    "        \"\"\"plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(left_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Left Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(right_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Right Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\"\"\"\n",
    "\n",
    "    else:  # single artwork\n",
    "        splitted = imgs_val\n",
    "        im, mask, output, _ = background_remover.remove_background_morphological_gradient(img)\n",
    "\n",
    "        # Crop to mask bounding box (remove black)\n",
    "        cropped = background_remover.crop_to_mask_rectangle(img, mask)\n",
    "\n",
    "        # Extract descriptor\n",
    "        #kps = detect_keypoints(cropped, METHOD)\n",
    "        desc = compute_hog_descriptor(cropped)\n",
    "            \n",
    "        desc_query.append([desc])  # keep structure consistent\n",
    "        \n",
    "        \"\"\"plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"{img_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "# stack DB descriptors into a matrix so cosine_similarity is fast\n",
    "db_mat = np.vstack(db_descs)   # shape (N_db, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a75854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ mAP@1 = 0.3780\n",
      "✅ mAP@5 = 0.4065\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Compute mAP@1 and mAP@5 ---\n",
    "def compute_map_at_k(desc_query, desc_gt, gt_corresps, k=5):\n",
    "    \"\"\"\n",
    "    Compute mean Average Precision at K.\n",
    "    If a query image has multiple artworks, we pair each sub-descriptor with its matching GT index\n",
    "    (i.e., descs[j] -> gt_corresps[i][j]) when lengths match.\n",
    "    \"\"\"\n",
    "    aps = []\n",
    "\n",
    "    for i, descs in enumerate(desc_query):\n",
    "        q_gt = gt_corresps[i]\n",
    "        # Ensure list\n",
    "        if not isinstance(q_gt, list):\n",
    "            q_gt = [q_gt]\n",
    "\n",
    "        for desc in descs:\n",
    "            sims = cosine_similarity([desc], desc_gt)[0]\n",
    "            ranked_indices = np.argsort(-sims)[:k]\n",
    "\n",
    "            num_relevant = len(q_gt)\n",
    "            num_correct = 0\n",
    "            precision_at_i = []\n",
    "\n",
    "            for rank, idx in enumerate(ranked_indices, start=1):\n",
    "                if idx in q_gt:\n",
    "                    num_correct += 1\n",
    "                    precision_at_i.append(num_correct / rank)\n",
    "\n",
    "            ap = np.sum(precision_at_i) / num_relevant if num_relevant > 0 else 0\n",
    "            aps.append(ap)\n",
    "\n",
    "    return float(np.mean(aps)) if aps else 0.0\n",
    "\n",
    "\n",
    "\n",
    "map1 = compute_map_at_k(desc_query, db_descs, gt_corresps, k=1)\n",
    "map5 = compute_map_at_k(desc_query, db_descs, gt_corresps, k=5)\n",
    "\n",
    "print(f\"\\n✅ mAP@1 = {map1:.4f}\")\n",
    "print(f\"✅ mAP@5 = {map5:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
