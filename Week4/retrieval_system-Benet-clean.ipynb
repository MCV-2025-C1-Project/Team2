{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e0c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Retrieval system using HOG descriptors + mAP@1 and mAP@5\n",
    "# This notebook:\n",
    "# 1. Builds (or loads) HOG descriptors for the database (BBDD)\n",
    "# 2. Extracts HOG for the query images\n",
    "# 3. Retrieves the most similar database images using cosine similarity\n",
    "# 4. Evaluates using mAP@1 and mAP@5 based on gt_corresps.pkl\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from noise_filter import preprocess_image\n",
    "import background_remover_w2 as background_remover\n",
    "from image_split import split_images\n",
    "from image_split_team5 import segment_multiple_paintings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- paths (adjust to your structure) ---\n",
    "QUERY_FOLDER = \"../Data/Week4/qsd1_w4/\"     # query images\n",
    "DB_FOLDER    = \"../Data/BBDD/\"        # database (gallery) images\n",
    "GT_PATH      = \"../Data/Week4/qsd1_w4/gt_corresps.pkl\"\n",
    "\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea714a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    Loads all .jpg/ images from a folder, sorted by filename.\n",
    "    Returns:\n",
    "        names: list of filenames\n",
    "        imgs:  list of loaded cv2 images\n",
    "    \"\"\"\n",
    "    names = sorted(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(folder)\n",
    "            if f.lower().endswith((\".jpg\"))\n",
    "        ]\n",
    "    )\n",
    "    imgs = []\n",
    "    for name in names:\n",
    "        path = os.path.join(folder, name)\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Could not read {path}\")\n",
    "            continue\n",
    "        imgs.append(img)\n",
    "    return names, imgs\n",
    "\n",
    "\n",
    "def precision_at_k(retrieved_indices, gt_indices, k):\n",
    "    \"\"\"\n",
    "    Compute precision@k for one query.\n",
    "\n",
    "    retrieved_indices: list of database indices sorted by similarity (best first)\n",
    "    gt_indices: list of correct database indices for that query (can be 1 or more)\n",
    "    k: cutoff (1, 5, ...)\n",
    "\n",
    "    precision@k = (# of retrieved items in top-k that are in GT) / k\n",
    "    \"\"\"\n",
    "    retrieved_k = retrieved_indices[:k]\n",
    "    hits = sum(1 for r in retrieved_k if r in gt_indices)\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def mean_average_precision_at_k(all_retrieved, all_gts, k):\n",
    "    \"\"\"\n",
    "    Compute mean precision@k over all queries.\n",
    "    (Many assignments call this mAP@k when GT is small.)\n",
    "    \"\"\"\n",
    "    assert len(all_retrieved) == len(all_gts)\n",
    "    precisions = []\n",
    "    for retrieved, gts in zip(all_retrieved, all_gts):\n",
    "        p = precision_at_k(retrieved, gts, k)\n",
    "        precisions.append(p)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "def validate_split(is_split, imgs, min_size_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Validate the result of segment_multiple_paintings.\n",
    "\n",
    "    Parameters:\n",
    "        is_split (bool): Whether the segmentation said it's split.\n",
    "        imgs (list or np.ndarray): List [img1, img2] or a single image.\n",
    "        min_size_ratio (float): Minimum ratio (relative to original image width/height)\n",
    "                                for a crop to be considered valid.\n",
    "    Returns:\n",
    "        (bool, list or np.ndarray): same format as input but corrected.\n",
    "    \"\"\"\n",
    "    # If no split, nothing to do\n",
    "    if not is_split:\n",
    "        return False, imgs\n",
    "\n",
    "    # If there are not exactly 2 images, return as not split\n",
    "    if not isinstance(imgs, (list, tuple)) or len(imgs) != 2:\n",
    "        return False, imgs\n",
    "\n",
    "    img1, img2 = imgs\n",
    "\n",
    "    # Compute relative sizes compared to original (assume same height)\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    total_width = w1 + w2\n",
    "    total_height = max(h1, h2)\n",
    "\n",
    "    # Check each crop relative to the original combined width\n",
    "    valid_left  = w1 / total_width  > min_size_ratio\n",
    "    valid_right = w2 / total_width  > min_size_ratio\n",
    "    valid_height1 = h1 / total_height > min_size_ratio\n",
    "    valid_height2 = h2 / total_height > min_size_ratio\n",
    "\n",
    "    # Only keep crops that are not too small\n",
    "    valid_imgs = []\n",
    "    if valid_left and valid_height1:\n",
    "        valid_imgs.append(img1)\n",
    "    if valid_right and valid_height2:\n",
    "        valid_imgs.append(img2)\n",
    "\n",
    "    # Decide if it's still a valid split\n",
    "    if len(valid_imgs) == 2:\n",
    "        return True, valid_imgs\n",
    "    elif len(valid_imgs) == 1:\n",
    "        # Only one valid crop left ‚Üí treat as not split\n",
    "        return False, valid_imgs[0]\n",
    "    else:\n",
    "        # none valid? probably invalid segmentation\n",
    "        return False, imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447ef7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hog_descriptor(\n",
    "    img_bgr,\n",
    "    size=(128, 128),\n",
    "    cell=(4, 4),\n",
    "    block=(16, 16),\n",
    "    block_stride=(8, 8),\n",
    "    nbins=9,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute a HOG descriptor for a BGR image.\n",
    "    We:\n",
    "    1. convert to grayscale\n",
    "    2. resize to a fixed size so all descriptors have the same length\n",
    "    3. compute HOG\n",
    "    4. L2-normalize the final vector\n",
    "    \"\"\"\n",
    "    # 1) BGR -> Gray\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    # 2) fixed resize to make descriptor length stable\n",
    "    gray = cv2.resize(gray, size)\n",
    "\n",
    "    # 3) create HOG object with consistent parameters\n",
    "    hog = cv2.HOGDescriptor(\n",
    "        _winSize=size,\n",
    "        _blockSize=block,\n",
    "        _blockStride=block_stride,\n",
    "        _cellSize=cell,\n",
    "        _nbins=nbins,\n",
    "    )\n",
    "    desc = hog.compute(gray)  # shape (N, 1)\n",
    "    desc = desc.flatten().astype(np.float32)\n",
    "\n",
    "    # 4) L2 normalization (good for cosine and distance-based retrieval)\n",
    "    norm = np.linalg.norm(desc)\n",
    "    if norm > 0:\n",
    "        desc = desc / norm\n",
    "\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c557c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sift_desc(img_bgr, nfeatures=1200, rootsift=False, img_name=\"\"):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create(nfeatures=nfeatures)\n",
    "    _, des = sift.detectAndCompute(gray, None)\n",
    "    if des is None:\n",
    "        print(f\"‚ö†Ô∏è Warning: No SIFT descriptors found for {img_name}.\")\n",
    "        return None\n",
    "    des = des.astype(np.float32)\n",
    "    if rootsift:\n",
    "        des /= (des.sum(axis=1, keepdims=True) + 1e-12)\n",
    "        des = np.sqrt(des, out=des)\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74637338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loading DB descriptors from results/descriptors_db_sift.pkl\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "# 1. Build or load database descriptors\n",
    "# # where to store precomputed DB descriptors\n",
    "descriptor = \"SIFT\"\n",
    "DESC_DB_PATH = \"results/descriptors_db_sift.pkl\"\n",
    "\n",
    "if os.path.exists(DESC_DB_PATH):\n",
    "    print(f\"‚úÖ Loading DB descriptors from {DESC_DB_PATH}\")\n",
    "    with open(DESC_DB_PATH, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        db_descs = data[\"desc_gt\"]    # list of numpy arrays\n",
    "        db_names = data[\"gt_names\"]   # list of image filenames\n",
    "else:\n",
    "    print(f\"üß† Computing {descriptor} descriptors for database images...\")\n",
    "    db_names, db_imgs = load_images_from_folder(DB_FOLDER)\n",
    "    db_descs = []\n",
    "    for img, name in zip(db_imgs, db_names):\n",
    "        print(\"Processing image\",name)\n",
    "        if descriptor == \"SIFT\":\n",
    "            d = compute_sift_desc(img, rootsift=True, img_name=name)\n",
    "        elif descriptor == \"HOG\":   \n",
    "            d = compute_hog_descriptor(img)\n",
    "        db_descs.append(d)\n",
    "\n",
    "    # store only numpy arrays (serializable) ‚Üí no cv2.KeyPoint here\n",
    "    with open(DESC_DB_PATH, \"wb\") as f:\n",
    "        pickle.dump({\"desc_gt\": db_descs, \"gt_names\": db_names}, f)\n",
    "    print(f\"‚úÖ Saved DB descriptors to {DESC_DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65aa4876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading query images...\n",
      "üì• Loading ground-truth correspondences...\n",
      "‚Üí 30 GT entries loaded\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 2. Load query images and ground-truth correspondences\n",
    "\n",
    "print(\"üì• Loading query images...\")\n",
    "q_names, q_imgs = load_images_from_folder(QUERY_FOLDER)\n",
    "\n",
    "print(\"üì• Loading ground-truth correspondences...\")\n",
    "with open(GT_PATH, \"rb\") as f:\n",
    "    gt_corresps = pickle.load(f)   # e.g. [[236], [107], [280, 285], ...]\n",
    "print(f\"‚Üí {len(gt_corresps)} GT entries loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33d529ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Computing SIFT for queries...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 117890320 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m im, mask, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m background_remover\u001b[38;5;241m.\u001b[39mremove_background_morphological_gradient(img)\n\u001b[0;32m     28\u001b[0m cropped \u001b[38;5;241m=\u001b[39m background_remover\u001b[38;5;241m.\u001b[39mcrop_to_mask_rectangle(img, mask)\n\u001b[1;32m---> 29\u001b[0m desc_single \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_sift_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrootsift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m desc_query\u001b[38;5;241m.\u001b[39mappend([desc_single])  \u001b[38;5;66;03m# still a list\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mcompute_sift_desc\u001b[1;34m(img_bgr, nfeatures, rootsift, img_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_bgr, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      3\u001b[0m sift \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mSIFT_create(nfeatures\u001b[38;5;241m=\u001b[39mnfeatures)\n\u001b[1;32m----> 4\u001b[0m _, des \u001b[38;5;241m=\u001b[39m \u001b[43msift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectAndCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m des \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è Warning: No SIFT descriptors found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 117890320 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "desc_query = []   # list of [desc_left, desc_right] or [desc_single]\n",
    "\n",
    "print(f\"üß† Computing {descriptor} for queries...\")\n",
    "for img, img_name in zip(q_imgs, q_names):\n",
    "    img = preprocess_image(img)\n",
    "    bool_split, splitted_imgs = segment_multiple_paintings(img)\n",
    "    ok_split, parts = validate_split(bool_split, splitted_imgs)\n",
    "\n",
    "    if ok_split:\n",
    "        left_artwork, right_artwork = parts\n",
    "        iml, left_mask, *_ = background_remover.remove_background_morphological_gradient(left_artwork)\n",
    "        imr, right_mask, *_ = background_remover.remove_background_morphological_gradient(right_artwork)\n",
    "\n",
    "        left_cropped  = background_remover.crop_to_mask_rectangle(left_artwork, left_mask)\n",
    "        right_cropped = background_remover.crop_to_mask_rectangle(right_artwork, right_mask)\n",
    "\n",
    "        if descriptor == \"SIFT\":\n",
    "            desc_left  = compute_sift_desc(left_cropped,  rootsift=True)\n",
    "            desc_right = compute_sift_desc(right_cropped, rootsift=True)\n",
    "        else:\n",
    "            raise ValueError(\"Only SIFT in this baseline\")\n",
    "\n",
    "        # keep consistent list structure\n",
    "        desc_query.append([desc_left, desc_right])\n",
    "\n",
    "    else:\n",
    "        im, mask, *_ = background_remover.remove_background_morphological_gradient(img)\n",
    "        cropped = background_remover.crop_to_mask_rectangle(img, mask)\n",
    "        desc_single = compute_sift_desc(cropped, rootsift=True)\n",
    "        desc_query.append([desc_single])  # still a list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ee00a",
   "metadata": {},
   "source": [
    "## With no unknown artworks detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab750c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# --- FLANN 2-NN + Lowe ratio; returns \"good match count\" ---\n",
    "_flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=8),\n",
    "                               dict(checks=64))\n",
    "\n",
    "def good_match_count(desQ, desD, ratio=0.76):\n",
    "    if desQ is None or desD is None or len(desQ)==0 or len(desD)==0:\n",
    "        return 0\n",
    "    knn = _flann.knnMatch(desQ, desD, k=2)\n",
    "    good = 0\n",
    "    for m, n in knn:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good += 1\n",
    "    return good\n",
    "\n",
    "def rank_db_for_query_multi(desc_crops, db_descs, ratio=0.76):\n",
    "    \"\"\"\n",
    "    desc_crops: list of descriptor arrays for this query (len=1 or 2)\n",
    "    db_descs:   list of descriptor arrays (one per DB image)\n",
    "    returns:    ranked list of (db_idx, score) sorted desc by score\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i, desD in enumerate(db_descs):\n",
    "        best = 0\n",
    "        for desQ in desc_crops:  # MAX merge across crops\n",
    "            c = good_match_count(desQ, desD, ratio)\n",
    "            if c > best:\n",
    "                best = c\n",
    "        scores.append((i, best))\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores  # full ranking\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10, skip_unknown=True):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    map_score = 0.0\n",
    "    total_pics = 0\n",
    "    for idx, p in enumerate(predicted):\n",
    "        if len(p) == 2:\n",
    "            # print(f\"actual[idx]: {actual[idx]}, {actual[idx][0]}, {actual[idx][1]}\")\n",
    "            apk_score1 = apk([actual[idx][0]], p[0], k)\n",
    "            apk_score2 = apk([actual[idx][1]], p[1], k)\n",
    "            map_score += apk_score1 + apk_score2\n",
    "            total_pics += 2\n",
    "            ### HERE WE SHOULD AVERAGE THE TWO SCORES?\n",
    "            # print(f\"Scores for query {idx}: Left AP@{k}={apk_score1:.4f}, Right AP@{k}={apk_score2:.4f}\")\n",
    "        elif actual[idx] == [-1] and skip_unknown:\n",
    "            print(f\"Scores for query {idx}: Unknown artwork, skipped.\")\n",
    "            continue\n",
    "        else:\n",
    "            apk_score1 = apk(actual[idx], p, k)\n",
    "            map_score += apk_score1\n",
    "            total_pics += 1\n",
    "            # print(f\"Scores for query {idx}: Single AP@{k}={apk_score1:.4f}\")\n",
    "\n",
    "    return map_score / total_pics if total_pics > 0 else 0.0\n",
    "\n",
    "def compute_map_at_k(desc_query, db_descs, gt_corresps, ratio=0.76):\n",
    "    \"\"\"\n",
    "    desc_query:  list where each element is [desc_single] or [desc_left, desc_right]\n",
    "    db_descs:    list of descriptor arrays, one per DB image\n",
    "    gt_corresps: list; each entry is an int, list of ints, or [-1]\n",
    "    \"\"\"\n",
    "    predicted = []\n",
    "    # for qi, desc_crops in tqdm(enumerate(desc_query), total=len(desc_query)):\n",
    "    for qi, desc_crops in enumerate(desc_query):\n",
    "        # Normalize GT format\n",
    "        q_gt = gt_corresps[qi]\n",
    "        if len(q_gt) == 2 and len(desc_crops) == 2:\n",
    "            # relevants = [g for g in q_gt if g != -1]\n",
    "            list_ranked_indices = []\n",
    "            for desc_crop in desc_crops:\n",
    "                ranked = rank_db_for_query_multi([desc_crop], db_descs, ratio=ratio)\n",
    "                ranked_indices, ranked_scores = zip(*ranked)\n",
    "                list_ranked_indices.append(ranked_indices)\n",
    "                #print all: ranked_indices, ranked_scores, gt... of the first 10 ranked\n",
    "                for i in range(min(1, len(ranked_indices))):\n",
    "                    print(f\"Rank {i+1}: DB Index={ranked_indices[i]}, Score={ranked_scores[i]}\")\n",
    "                    print(f\"GT for query {qi}: {q_gt}\")\n",
    "\n",
    "        else:\n",
    "            ranked = rank_db_for_query_multi(desc_crops, db_descs, ratio=ratio)\n",
    "            list_ranked_indices, list_ranked_scores = zip(*ranked)\n",
    "            #print all: ranked_indices, ranked_scores, gt... of the first 10 ranked\n",
    "            for i in range(min(1, len(list_ranked_indices))):\n",
    "                print(f\"Rank {i+1}: DB Index={list_ranked_indices[i]}, Score={list_ranked_scores[i]}\")\n",
    "                print(f\"GT for query {qi}: {q_gt}\")\n",
    "        \n",
    "        predicted.append(list_ranked_indices)\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "# pred = compute_map_at_k(desc_query, db_descs, gt_corresps, ratio=0.76)    \n",
    "# map5 = mapk(gt_corresps, pred, k=5)\n",
    "# map1 = mapk(gt_corresps, pred, k=1)\n",
    "\n",
    "# print(f\"‚úÖ mAP@1 = {map1:.4f}\")\n",
    "# print(f\"‚úÖ mAP@5 = {map5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a06367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ mAP@1 = 0.6667\n",
      "‚úÖ mAP@5 = 0.6731\n"
     ]
    }
   ],
   "source": [
    "pred = compute_map_at_k(desc_query, db_descs, gt_corresps, ratio=0.76)    \n",
    "map5 = mapk(gt_corresps, pred, k=5, skip_unknown=False)\n",
    "map1 = mapk(gt_corresps, pred, k=1, skip_unknown=False)\n",
    "\n",
    "print(f\"‚úÖ mAP@1 = {map1:.4f}\")\n",
    "print(f\"‚úÖ mAP@5 = {map5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a9554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for query 0: Unknown artwork, skipped.\n",
      "Scores for query 7: Unknown artwork, skipped.\n",
      "Scores for query 11: Unknown artwork, skipped.\n",
      "Scores for query 12: Unknown artwork, skipped.\n",
      "Scores for query 14: Unknown artwork, skipped.\n",
      "Scores for query 17: Unknown artwork, skipped.\n",
      "Scores for query 19: Unknown artwork, skipped.\n",
      "Scores for query 21: Unknown artwork, skipped.\n",
      "Scores for query 26: Unknown artwork, skipped.\n",
      "Scores for query 29: Unknown artwork, skipped.\n",
      "Scores for query 0: Unknown artwork, skipped.\n",
      "Scores for query 7: Unknown artwork, skipped.\n",
      "Scores for query 11: Unknown artwork, skipped.\n",
      "Scores for query 12: Unknown artwork, skipped.\n",
      "Scores for query 14: Unknown artwork, skipped.\n",
      "Scores for query 17: Unknown artwork, skipped.\n",
      "Scores for query 19: Unknown artwork, skipped.\n",
      "Scores for query 21: Unknown artwork, skipped.\n",
      "Scores for query 26: Unknown artwork, skipped.\n",
      "Scores for query 29: Unknown artwork, skipped.\n",
      "‚úÖ mAP@1 = 0.8966\n",
      "‚úÖ mAP@5 = 0.9052\n"
     ]
    }
   ],
   "source": [
    "# pred = compute_map_at_k(desc_query, db_descs, gt_corresps, ratio=0.76)    \n",
    "map5 = mapk(gt_corresps, pred, k=5)\n",
    "map1 = mapk(gt_corresps, pred, k=1)\n",
    "\n",
    "print(f\"‚úÖ mAP@1 = {map1:.4f}\")\n",
    "print(f\"‚úÖ mAP@5 = {map5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6916ea6",
   "metadata": {},
   "source": [
    "## With unknown artworks detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe975a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "# ---------- Matching primitives ----------\n",
    "\n",
    "_flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=8),\n",
    "                               dict(checks=64))\n",
    "\n",
    "def good_match_count(desQ: Union[np.ndarray, None],\n",
    "                     desD: Union[np.ndarray, None],\n",
    "                     ratio: float = 0.76) -> int:\n",
    "    \"\"\"\n",
    "    2-NN + Lowe ratio test. Returns number of 'good' matches.\n",
    "    \"\"\"\n",
    "    if desQ is None or desD is None or len(desQ) == 0 or len(desD) == 0:\n",
    "        return 0\n",
    "    knn = _flann.knnMatch(desQ, desD, k=2)\n",
    "    good = 0\n",
    "    for m, n in knn:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good += 1\n",
    "    return good\n",
    "\n",
    "def rank_db_with_scores(desQ: np.ndarray,\n",
    "                        db_descs: List[np.ndarray],\n",
    "                        ratio: float = 0.76) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Returns list sorted desc by score: [(db_idx, good_match_count), ...]\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i, desD in enumerate(db_descs):\n",
    "        c = good_match_count(desQ, desD, ratio)\n",
    "        scores.append((i, c))\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores\n",
    "\n",
    "def decide_unknown_from_scores(scores: List[Tuple[int,int]],\n",
    "                               T_abs: int = 12,\n",
    "                               T_ratio: float = 1.4) -> bool:\n",
    "    \"\"\"\n",
    "    Unknown if:\n",
    "      - low absolute matches (best < T_abs), OR\n",
    "      - no clear winner (best/second < T_ratio)\n",
    "    \"\"\"\n",
    "    if not scores:\n",
    "        return True\n",
    "    best = scores[0][1]\n",
    "    second = scores[1][1] if len(scores) > 1 else 0\n",
    "    if best < T_abs:\n",
    "        return True\n",
    "    if second > 0 and (best / (second + 1e-9)) < T_ratio:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# ---------- Prediction (your shape preserved) ----------\n",
    "\n",
    "def predict_with_unknowns(desc_query: List[List[Union[np.ndarray, None]]],\n",
    "                          db_descs: List[np.ndarray],\n",
    "                          topK: int = 10,\n",
    "                          ratio: float = 0.76,\n",
    "                          T_abs: int = 12, T_ratio: float = 1.4):\n",
    "    \"\"\"\n",
    "    Keeps your output shape:\n",
    "      - single artwork: [ [db_idx0, db_idx1, ...] ]  or [[-1]]\n",
    "      - two artworks:   [ [rank_left...], [rank_right...] ]  (each may be [-1])\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for desc_crops in desc_query:\n",
    "        crop_preds = []\n",
    "        for desQ in desc_crops:\n",
    "            if desQ is None or len(desQ) == 0:\n",
    "                crop_preds.append([-1])\n",
    "                continue\n",
    "            scores = rank_db_with_scores(desQ, db_descs, ratio=ratio)\n",
    "            ranked_indices = [i for i, _ in scores]\n",
    "            if decide_unknown_from_scores(scores, T_abs=T_abs, T_ratio=T_ratio):\n",
    "                crop_preds.append([-1])\n",
    "            else:\n",
    "                crop_preds.append(ranked_indices[:topK])\n",
    "        predictions.append(crop_preds)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# ---------- Evaluation (robust to split‚â†GT) ----------\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10, skip_unknown=True):\n",
    "    \"\"\"\n",
    "    Robust to 1‚Üî2 splits:\n",
    "      - 1 GT vs 2 preds: take BEST of the two\n",
    "      - 2 GT vs 2 preds: best pairing average\n",
    "      - 2 GT vs 1 pred: evaluate one list vs both GTs\n",
    "      - GT [-1]: skip or count as 0 (depending on skip_unknown)\n",
    "    \"\"\"\n",
    "    map_score = 0.0\n",
    "    total_pics = 0\n",
    "    for idx, p in enumerate(predicted):\n",
    "        if len(p) == 2:\n",
    "            if len(actual[idx]) == 2:\n",
    "                apk_score1 = apk([actual[idx][0]], p[0], k)\n",
    "                apk_score2 = apk([actual[idx][1]], p[1], k)\n",
    "                map_score += apk_score1 + apk_score2\n",
    "                total_pics += 2\n",
    "            else:\n",
    "                apk_score1 = apk(actual[idx], p[0], k)\n",
    "                map_score += apk_score1\n",
    "                total_pics += 1\n",
    "        elif actual[idx] == [-1] and skip_unknown:\n",
    "            print(f\"Scores for query {idx}: Unknown artwork, skipped.\")\n",
    "            continue\n",
    "        else:\n",
    "            apk_score1 = apk(actual[idx], p, k)\n",
    "            map_score += apk_score1\n",
    "            total_pics += 1\n",
    "\n",
    "    return map_score / total_pics if total_pics > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2140c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ mAP@1 = 0.4359\n",
      "‚úÖ mAP@5 = 0.4359\n"
     ]
    }
   ],
   "source": [
    "pred = predict_with_unknowns(desc_query, db_descs, topK=10, ratio=0.76, T_abs=12, T_ratio=1.4)\n",
    "map5 = mapk(gt_corresps, pred, k=5,  skip_unknown=False)\n",
    "map1 = mapk(gt_corresps, pred, k=1,  skip_unknown=False)\n",
    "print(f\"‚úÖ mAP@1 = {map1:.4f}\")\n",
    "print(f\"‚úÖ mAP@5 = {map5:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCV-C1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
