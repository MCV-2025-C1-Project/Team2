{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d30aa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 00000.jpg ...\n",
      "Processing 00001.jpg ...\n",
      "Processing 00002.jpg ...\n",
      "Processing 00003.jpg ...\n",
      "Processing 00004.jpg ...\n",
      "Processing 00005.jpg ...\n",
      "Processing 00006.jpg ...\n",
      "Processing 00007.jpg ...\n",
      "Processing 00008.jpg ...\n",
      "Processing 00009.jpg ...\n",
      "Processing 00010.jpg ...\n",
      "Processing 00011.jpg ...\n",
      "Processing 00012.jpg ...\n",
      "Processing 00013.jpg ...\n",
      "Processing 00014.jpg ...\n",
      "Processing 00015.jpg ...\n",
      "Processing 00016.jpg ...\n",
      "Processing 00017.jpg ...\n",
      "Processing 00018.jpg ...\n",
      "Processing 00019.jpg ...\n",
      "Processing 00020.jpg ...\n",
      "Processing 00021.jpg ...\n",
      "Processing 00022.jpg ...\n",
      "Processing 00023.jpg ...\n",
      "Processing 00024.jpg ...\n",
      "Processing 00025.jpg ...\n",
      "Processing 00026.jpg ...\n",
      "Processing 00027.jpg ...\n",
      "Processing 00028.jpg ...\n",
      "Processing 00029.jpg ...\n",
      "\n",
      "✅ mAP@1 = 0.3611\n",
      "✅ mAP@5 = 0.4255\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from background_removal_exp import background_remover_w2 as background_remover\n",
    "# from background_removal_exp import bckg_rmv as background_remover\n",
    "from descriptors import preprocess_image, extract_descriptor, extract_descriptors\n",
    "from image_split import split_images\n",
    "\n",
    "# Paths\n",
    "IMG_FOLDER = \"../Data/Week3/qsd2_w3/\"\n",
    "IMG_FOLDER_GT = \"../Data/Week3/BBDD/\"\n",
    "GT_CORRESPS_PATH = \"../Data/Week3/qsd2_w3/gt_corresps.pkl\"\n",
    "DESC_GT_PATH = \"results/descriptors_gt.pkl\"\n",
    "\n",
    "# --- 1. Load or compute GT descriptors ---\n",
    "\n",
    "def build_gt_descriptors(gt_folder, extractor):\n",
    "    names = sorted([f for f in os.listdir(gt_folder) if f.lower().endswith(('.jpg','.png','.jpeg'))])\n",
    "    descs = []\n",
    "    for name in names:\n",
    "        img = cv2.imread(os.path.join(gt_folder, name))\n",
    "        # === Do the SAME as query ===\n",
    "        # 1) (Optional) convert BGR->RGB if your descriptors expect RGB\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 2) preprocess\n",
    "        img_p = preprocess_image(img)\n",
    "\n",
    "        # 3) background removal + crop\n",
    "        im, mask, _, _ = background_remover.remove_background_morphological_gradient(img_p)\n",
    "        img_c = crop_to_mask_rectangle(img_p, mask)\n",
    "\n",
    "        # 4) descriptor (L2 normalize)\n",
    "        d = extract_descriptor(img_c)\n",
    "        d = d / (np.linalg.norm(d) + 1e-12)\n",
    "        descs.append(d)\n",
    "    return np.vstack(descs), names\n",
    "\n",
    "\n",
    "if os.path.exists(DESC_GT_PATH):\n",
    "    # Optional: delete the cache to rebuild with the new consistent pipeline\n",
    "    with open(DESC_GT_PATH, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        desc_gt = data[\"desc_gt\"]\n",
    "        gt_names = data[\"gt_names\"]\n",
    "else:\n",
    "    desc_gt, gt_names = build_gt_descriptors(IMG_FOLDER_GT, extract_descriptor)\n",
    "    os.makedirs(os.path.dirname(DESC_GT_PATH), exist_ok=True)\n",
    "    with open(DESC_GT_PATH, \"wb\") as f:\n",
    "        pickle.dump({\"desc_gt\": desc_gt, \"gt_names\": gt_names}, f)\n",
    "\n",
    "# --- 2. Load GT correspondences ---\n",
    "with open(GT_CORRESPS_PATH, \"rb\") as f:\n",
    "    gt_corresps = pickle.load(f)\n",
    "\n",
    "\n",
    "def crop_to_mask_rectangle(image, mask):\n",
    "    \"\"\"Crop the image to the rectangular bounding box of the mask (removes black areas).\"\"\"\n",
    "    # Ensure mask is binary (0 or 255)\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    # Find nonzero points (foreground)\n",
    "    coords = cv2.findNonZero(mask)\n",
    "    if coords is None:\n",
    "        return image  # fallback if mask is empty\n",
    "\n",
    "    # Get bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "\n",
    "    # Crop the original image to the bounding box\n",
    "    cropped = image[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "\n",
    "# --- 3. Process all images in the folder ---\n",
    "def _l2norm(x):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    n = np.linalg.norm(x) + 1e-12\n",
    "    return x / n\n",
    "\n",
    "image_names = sorted([f for f in os.listdir(IMG_FOLDER) if f.endswith('.jpg')])\n",
    "desc_query = []\n",
    "\n",
    "for img_idx, img_name in enumerate(image_names):\n",
    "    print(f\"Processing {img_name} ...\")\n",
    "    img_path = os.path.join(IMG_FOLDER, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Skipping {img_name}: could not read image.\")\n",
    "        continue\n",
    "\n",
    "    # Split possible multiple artworks\n",
    "    splitted = split_images(img)\n",
    "\n",
    "    if splitted[0] is True:\n",
    "        splitted = splitted[1]  # two artworks detected\n",
    "        left_artwork, right_artwork = splitted\n",
    "\n",
    "        left_artwork = preprocess_image(left_artwork)\n",
    "        right_artwork = preprocess_image(right_artwork)\n",
    "\n",
    "        iml, left_mask, left_output, _ = background_remover.remove_background_morphological_gradient(left_artwork)\n",
    "        imr, right_mask, right_output, _ = background_remover.remove_background_morphological_gradient(right_artwork)\n",
    "\n",
    "        # Crop each artwork to its mask bounding box (no black borders)\n",
    "        left_cropped = crop_to_mask_rectangle(left_artwork, left_mask)\n",
    "        right_cropped = crop_to_mask_rectangle(right_artwork, right_mask)\n",
    "\n",
    "        # Extract descriptors\n",
    "        desc_left  = _l2norm(extract_descriptor(left_cropped))\n",
    "        desc_right = _l2norm(extract_descriptor(right_cropped))\n",
    "\n",
    "        desc_query.append([desc_left, desc_right])\n",
    "        \n",
    "        \"\"\"plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(left_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Left Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(right_cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Right Artwork: {img_name}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\"\"\"\n",
    "\n",
    "    else:  # single artwork\n",
    "        splitted = splitted[1]  # single artwork\n",
    "        img = preprocess_image(splitted)\n",
    "        im, mask, output, _ = background_remover.remove_background_morphological_gradient(img)\n",
    "\n",
    "        # Crop to mask bounding box (remove black)\n",
    "        cropped = crop_to_mask_rectangle(img, mask)\n",
    "\n",
    "        # Extract descriptor\n",
    "        desc = _l2norm(extract_descriptor(cropped))\n",
    "        desc_query.append([desc])  # keep structure consistent\n",
    "        \n",
    "        \"\"\"plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"{img_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "# --- 4. Compute mAP@1 and mAP@5 ---\n",
    "def compute_map_at_k(desc_query, desc_gt, gt_corresps, k=5):\n",
    "    \"\"\"\n",
    "    Compute mean Average Precision at K.\n",
    "    If a query image has multiple artworks, we pair each sub-descriptor with its matching GT index\n",
    "    (i.e., descs[j] -> gt_corresps[i][j]) when lengths match.\n",
    "    \"\"\"\n",
    "    aps = []\n",
    "\n",
    "    for i, descs in enumerate(desc_query):\n",
    "        q_gt = gt_corresps[i]\n",
    "        # Ensure list\n",
    "        if not isinstance(q_gt, list):\n",
    "            q_gt = [q_gt]\n",
    "\n",
    "        # Case 1: same number of descriptors and GT labels → pair 1:1\n",
    "        if len(descs) == len(q_gt):\n",
    "            for j, desc in enumerate(descs):\n",
    "                sims = cosine_similarity([desc], desc_gt)[0]\n",
    "                ranked_indices = np.argsort(-sims)[:k]\n",
    "                # Only 1 relevant item for this subquery\n",
    "                rel = q_gt[j]\n",
    "                # Precision@rank if found within top-k\n",
    "                ap = 0.0\n",
    "                for rank, idx in enumerate(ranked_indices, start=1):\n",
    "                    if idx == rel:\n",
    "                        ap = 1.0 / rank\n",
    "                        break\n",
    "                aps.append(ap)\n",
    "        else:\n",
    "            # Fallback: multiple relevant labels for each sub-descriptor (your original logic)\n",
    "            for desc in descs:\n",
    "                sims = cosine_similarity([desc], desc_gt)[0]\n",
    "                ranked_indices = np.argsort(-sims)[:k]\n",
    "\n",
    "                num_relevant = len(q_gt)\n",
    "                num_correct = 0\n",
    "                precision_at_i = []\n",
    "\n",
    "                for rank, idx in enumerate(ranked_indices, start=1):\n",
    "                    if idx in q_gt:\n",
    "                        num_correct += 1\n",
    "                        precision_at_i.append(num_correct / rank)\n",
    "\n",
    "                ap = np.sum(precision_at_i) / num_relevant if num_relevant > 0 else 0\n",
    "                aps.append(ap)\n",
    "\n",
    "    return float(np.mean(aps)) if aps else 0.0\n",
    "\n",
    "\n",
    "\n",
    "map1 = compute_map_at_k(desc_query, desc_gt, gt_corresps, k=1)\n",
    "map5 = compute_map_at_k(desc_query, desc_gt, gt_corresps, k=5)\n",
    "\n",
    "print(f\"\\n✅ mAP@1 = {map1:.4f}\")\n",
    "print(f\"✅ mAP@5 = {map5:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCV-C1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
